{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/local/home/mhoerold/entrack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "import nibabel as nib\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.baum_vagan.vagan.model_wrapper import VAGanWrapper\n",
    "from src.baum_vagan.utils import ncc\n",
    "from src.data.streaming.vagan_streaming import MRIImagePair, AgeFixedDeltaStream\n",
    "from src.baum_vagan.utils import map_image_to_intensity_range\n",
    "from src.data.streaming.mri_streaming import MRISingleStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wrapper(smt_label):\n",
    "    config_path = os.path.join(\"data\", smt_label, \"config.yaml\")\n",
    "    model_dir = os.path.join(\"data\", smt_label, \"logdir\")\n",
    "    with open(config_path, 'r') as f:\n",
    "        model_config = yaml.load(f)\n",
    "    wrapper = VAGanWrapper(**model_config)\n",
    "    wrapper.vagan.load_weights(model_dir)\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hc_wrapper = load_wrapper('20180823-185855')\n",
    "ad_wrapper = load_wrapper('20180823-185845')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stream = lambda bs: ad_wrapper.data.testAD.next_batch(bs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dir = os.path.join('notebooks/vagan_generated/hc_vs_ad')\n",
    "if not os.path.exists(dump_dir):\n",
    "    os.makedirs(dump_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find train and validation patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_pairs = ad_wrapper.data.train_pairs + ad_wrapper.data.val_pairs + hc_wrapper.data.train_pairs + hc_wrapper.data.val_pairs\n",
    "train_patient_ids = set()\n",
    "for pair in train_val_pairs:\n",
    "    patient_id = hc_wrapper.data.get_patient_id(pair.fid1)\n",
    "    train_patient_ids.add(patient_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all test patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_config = copy.deepcopy(ad_wrapper.data.config)\n",
    "single_config[\"use_diagnoses\"] = ['healthy', 'health_ad']\n",
    "single_stream = MRISingleStream(single_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patient_ids = set()\n",
    "for fid in single_stream.all_file_ids:\n",
    "    all_patient_ids.add(single_stream.get_patient_id(fid))\n",
    "    \n",
    "hc_test_fids = set()\n",
    "ad_test_fids = set()\n",
    "for fid in single_stream.all_file_ids:\n",
    "    pid = single_stream.get_patient_id(fid)\n",
    "    if pid not in train_patient_ids:\n",
    "        diag = single_stream.get_diagnose(fid)\n",
    "        if diag == \"healthy\":\n",
    "            hc_test_fids.add(fid)\n",
    "        elif diag == \"health_ad\":\n",
    "            ad_test_fids.add(fid)\n",
    "            \n",
    "hc_test_fids = list(hc_test_fids)\n",
    "ad_test_fids = list(ad_test_fids)\n",
    "np.random.seed(11)\n",
    "np.random.shuffle(hc_test_fids)\n",
    "np.random.shuffle(ad_test_fids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_model(model, img, n_steps):\n",
    "    images = []\n",
    "    masks = []\n",
    "    # placeholder needs a second channel not used by generator\n",
    "    delta_channel = img * 0 + 1.0\n",
    "    img = np.concatenate((img, delta_channel, img), axis=-1)\n",
    "    img = np.array([img])  # make a batch of size 1\n",
    "    for _ in range(n_steps):\n",
    "        M = model.predict_mask(img)\n",
    "        masks.append(np.squeeze(M))\n",
    "        img += M\n",
    "        img[:, :, :, 1] = delta_channel[:, :, 0]\n",
    "        images.append(np.copy(np.squeeze(img[:, :, :, 0])))\n",
    "        # placeholder needs a second channel not used by generator\n",
    "        # img = np.concatenate((img, img), axis=-1)\n",
    "        \n",
    "    return images, masks\n",
    "\n",
    "def compare_hc_ad_images_and_masks(x_t0, t0, hc_images, hc_masks, ad_images, ad_masks):\n",
    "    # plot predictions\n",
    "    nrows = 5\n",
    "    ncols = len(hc_images) + 1\n",
    "    fsize = 4\n",
    "    plt.figure(figsize=(ncols * fsize, nrows * fsize))\n",
    "    # plot hc images\n",
    "    plt.subplot(nrows, ncols, 1)\n",
    "    plt.imshow(np.squeeze(x_t0), cmap='gray')\n",
    "    plt.title(\"x_t0, age={}\".format(str(t0)))\n",
    "    plt.axis('off')\n",
    "\n",
    "    for i, img in enumerate(hc_images):\n",
    "        plt.subplot(nrows, ncols, i + 2)\n",
    "        plt.imshow(np.squeeze(img), cmap='gray')\n",
    "        plt.title('HC Generated x_t{}'.format(i + 1))\n",
    "        plt.axis('off')\n",
    "\n",
    "    # plot masks\n",
    "    # concatenate differnce maps to plot with same scale\n",
    "    plt.subplot(nrows, ncols, (ncols + 1, ncols + len(hc_masks)))\n",
    "    mask_slices = [m for m in hc_masks]\n",
    "    mask_slices_im = np.hstack(tuple(mask_slices))\n",
    "    plt.imshow(mask_slices_im, cmap='bwr', vmin=-2, vmax=2)\n",
    "    plt.title(\"HC Generated difference maps\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # plot ad images\n",
    "    plt.subplot(nrows, ncols, 2 * ncols + 1)\n",
    "    plt.imshow(np.squeeze(x_t0), cmap='gray')\n",
    "    plt.title(\"x_t0, age={}\".format(str(t0)))\n",
    "    plt.axis('off')\n",
    "\n",
    "    for i, img in enumerate(ad_images):\n",
    "        plt.subplot(nrows, ncols, 2 * ncols + i + 2)\n",
    "        plt.imshow(np.squeeze(img), cmap='gray')\n",
    "        plt.title('AD Generated x_t{}'.format(i + 1))\n",
    "        plt.axis('off')\n",
    "\n",
    "    # plot masks\n",
    "    # concatenate differnce maps to plot with same scale\n",
    "    plt.subplot(nrows, ncols, (3 * ncols + 1, 3 * ncols + len(hc_masks)))\n",
    "    mask_slices = [m for m in ad_masks]\n",
    "    mask_slices_im = np.hstack(tuple(mask_slices))\n",
    "    plt.imshow(mask_slices_im, cmap='bwr', vmin=-2, vmax=2)\n",
    "    plt.title(\"AD Generated difference maps\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # HC to AD change\n",
    "    hc_ad_change = []\n",
    "    for ad_im, hc_im in zip(ad_images, hc_images):\n",
    "        change = np.squeeze(ad_im - hc_im)\n",
    "        hc_ad_change.append(change)\n",
    "        \n",
    "    plt.subplot(nrows, ncols, (4 * ncols + 1, 4 * ncols + len(hc_masks)))\n",
    "    mask_slices = [m for m in hc_ad_change]\n",
    "    mask_slices_im = np.hstack(tuple(mask_slices))\n",
    "    plt.imshow(mask_slices_im, cmap='bwr', vmin=-2, vmax=2)\n",
    "    plt.title(\"AD-HC\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    \n",
    "def plot_iterative_predictions(hc_model, ad_model, fid, delta):\n",
    "    # Use normalization of trained model\n",
    "    # print(pair.get_age_delta())\n",
    "    # print(pair.streamer.get_image_label(pair.fid1))\n",
    "    t0 = round(single_stream.get_exact_age(fid), 2)\n",
    "    \n",
    "    # get some pair and load image\n",
    "    some_pair = hc_wrapper.data.train_pairs[0]\n",
    "    x_t0 = some_pair.load_image(fid)\n",
    "\n",
    "    n_steps = delta\n",
    "    hc_images, hc_masks = iterate_model(hc_model, x_t0, n_steps)\n",
    "    ad_images, ad_masks = iterate_model(ad_model, x_t0, n_steps)\n",
    "\n",
    "    # dump\n",
    "    pid = single_stream.get_patient_id(fid)\n",
    "    out_path = os.path.join(dump_dir, \"{}.npz\".format(pid))\n",
    "    np.savez(out_path, hc_fake=hc_images, ad_fake=ad_images)\n",
    "    \n",
    "    compare_hc_ad_images_and_masks(x_t0, t0, hc_images, hc_masks, ad_images, ad_masks)\n",
    "    \n",
    "    \n",
    "\n",
    "plot_iterative_predictions(hc_wrapper.vagan, ad_wrapper.vagan, ad_test_fids[2], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very far predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_far_prediction(hc_model, ad_model, fid, deltas=[10, 20, 30]):\n",
    "    # Use normalization of trained model\n",
    "    # print(pair.get_age_delta())\n",
    "    # print(pair.streamer.get_image_label(pair.fid1))\n",
    "    t0 = round(single_stream.get_exact_age(fid), 2)\n",
    "    \n",
    "    # get some pair and load image\n",
    "    some_pair = hc_wrapper.data.train_pairs[0]\n",
    "    x_t0 = some_pair.load_image(fid)\n",
    "    \n",
    "    def get_slice(img):\n",
    "        return np.squeeze(img)\n",
    "    \n",
    "    def far_preds(x, model):\n",
    "        cur_inp = x\n",
    "        preds = []\n",
    "        for i, delta in enumerate(deltas):\n",
    "            steps = delta\n",
    "            if i > 0:\n",
    "                steps = deltas[i] - deltas[i - 1]\n",
    "\n",
    "            images, _ = iterate_model(model, cur_inp, steps)\n",
    "            cur_inp = images[len(images) - 1][:, :]\n",
    "            cur_inp = np.reshape(cur_inp, tuple(list(cur_inp.shape) + [1]))\n",
    "            preds.append(np.copy(cur_inp))\n",
    "            \n",
    "        diff_maps = []\n",
    "        diff_maps.append(get_slice(preds[0] - x))\n",
    "        for i in range(1, len(deltas)):\n",
    "            diff_map = get_slice(preds[i] - preds[i - 1])\n",
    "            diff_maps.append(diff_map)\n",
    "            \n",
    "        return preds, diff_maps\n",
    "    \n",
    "    hc_images, hc_masks = far_preds(x_t0, hc_model)\n",
    "    ad_images, ad_masks = far_preds(x_t0, ad_model)\n",
    "    compare_hc_ad_images_and_masks(x_t0, t0, hc_images, hc_masks, ad_images, ad_masks)\n",
    "    \n",
    "plot_far_prediction(hc_wrapper.vagan, ad_wrapper.vagan, ad_test_fids[2], deltas=[10, 20, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
