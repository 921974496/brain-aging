{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation patients count in Dict: ', 800, 'Train patients count in Dict:', 14370)\n",
      "('Train Class ', 0, 6218)\n",
      "('Valid Class ', 0, 400)\n",
      "('Train Class ', 1, 8152)\n",
      "('Valid Class ', 1, 400)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "os.chdir('/local/home/dhaziza/entrack')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "sys.path.append('/local/home/dhaziza/entrack/')\n",
    "\n",
    "from src.data.providers.py_streaming import get_train_test_filenames\n",
    "\n",
    "config = {\n",
    "    'classes': 2,\n",
    "    'data_paths': {\n",
    "        'datadir': '/local/ADNI_AIBL/ADNI_AIBL_T1_normalized/train_NC_AD/',\n",
    "        'class_labels': '/local/ADNI_AIBL/ADNI_AIBL_T1_normalized/py2/AIBL_ADNI_class_labels_T1_NC_AD.pkl',\n",
    "        'valid_data': '/local/ADNI_AIBL/ADNI_AIBL_T1_normalized/py2/AIBL_ADNI_valid_T1_NC_AD.pkl',\n",
    "        'train_data': '/local/ADNI_AIBL/ADNI_AIBL_T1_normalized/py2/AIBL_ADNI_train_T1_NC_AD.pkl',\n",
    "        'regex': '_normalized\\.nii\\.gz',\n",
    "        'split_on': '_normalized.nii.gz',\n",
    "    }\n",
    "}\n",
    "train, valid = get_train_test_filenames(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0[train]: Done 0 / 6218\n",
      "c0[train]: Done 300 / 6218\n",
      "c0[train]: Done 600 / 6218\n",
      "c0[train]: Done 900 / 6218\n",
      "c0[train]: Done 1200 / 6218\n",
      "c0[train]: Done 1500 / 6218\n",
      "c0[train]: Done 1800 / 6218\n",
      "c0[train]: Done 2100 / 6218\n",
      "c0[train]: Done 2400 / 6218\n",
      "c0[train]: Done 2700 / 6218\n",
      "c0[train]: Done 3000 / 6218\n",
      "c0[train]: Done 3300 / 6218\n",
      "c0[train]: Done 3600 / 6218\n",
      "c0[train]: Done 3900 / 6218\n",
      "c0[train]: Done 4200 / 6218\n",
      "c0[train]: Done 4500 / 6218\n",
      "c0[train]: Done 4800 / 6218\n",
      "c0[train]: Done 5100 / 6218\n",
      "c0[train]: Done 5400 / 6218\n",
      "c0[train]: Done 5700 / 6218\n",
      "c0[train]: Done 6000 / 6218\n",
      "c1[train]: Done 0 / 8152\n",
      "c1[train]: Done 300 / 8152\n",
      "c1[train]: Done 600 / 8152\n",
      "c1[train]: Done 900 / 8152\n",
      "c1[train]: Done 1200 / 8152\n",
      "c1[train]: Done 1500 / 8152\n",
      "c1[train]: Done 1800 / 8152\n",
      "c1[train]: Done 2100 / 8152\n",
      "c1[train]: Done 2400 / 8152\n",
      "c1[train]: Done 2700 / 8152\n",
      "c1[train]: Done 3000 / 8152\n",
      "c1[train]: Done 3300 / 8152\n",
      "c1[train]: Done 3600 / 8152\n",
      "c1[train]: Done 3900 / 8152\n",
      "c1[train]: Done 4200 / 8152\n",
      "c1[train]: Done 4500 / 8152\n",
      "c1[train]: Done 4800 / 8152\n",
      "c1[train]: Done 5100 / 8152\n",
      "c1[train]: Done 5400 / 8152\n",
      "c1[train]: Done 5700 / 8152\n",
      "c1[train]: Done 6000 / 8152\n",
      "c1[train]: Done 6300 / 8152\n",
      "c1[train]: Done 6600 / 8152\n",
      "c1[train]: Done 6900 / 8152\n",
      "c1[train]: Done 7200 / 8152\n",
      "c1[train]: Done 7500 / 8152\n",
      "c1[train]: Done 7800 / 8152\n",
      "c1[train]: Done 8100 / 8152\n",
      "c0[valid]: Done 0 / 400\n",
      "c0[valid]: Done 300 / 400\n",
      "c1[valid]: Done 0 / 400\n",
      "c1[valid]: Done 300 / 400\n"
     ]
    }
   ],
   "source": [
    "ROOT_DATA_DIR = 'notebooks/2d_crops'\n",
    "z_slices = range(20, 70, 2)\n",
    "def dump_files(files, _class, train, plot=False):\n",
    "    total_todo = len(files)\n",
    "    print_every = 300\n",
    "    train_text = 'train' if train else 'valid'\n",
    "    files.sort()\n",
    "    for i, f in enumerate(files):\n",
    "        data = nib.load(f).get_data()\n",
    "        for z in z_slices:\n",
    "            try:\n",
    "                os.makedirs('%s/z%d/c%d_z%d' % (ROOT_DATA_DIR, z, _class, z))\n",
    "            except OSError: # Directory exists\n",
    "                pass\n",
    "            save_to = '%s/z%d/c%d_z%d/%d_%s.jpg' % (\n",
    "                ROOT_DATA_DIR, z, _class, z, i, train_text)\n",
    "            sliced_data = data[:, :, z]\n",
    "            sliced_data = (sliced_data*10 + 128)\n",
    "            sliced_data = sliced_data.astype(np.uint8)\n",
    "            im = Image.fromarray(sliced_data)\n",
    "            im.save(save_to)\n",
    "        if i % print_every == 0:\n",
    "            print('c%d[%s]: Done %d / %d' % (_class, train_text, i, total_todo))\n",
    "        \n",
    "dump_files(train[0], 0, True)\n",
    "dump_files(train[1], 1, True)\n",
    "dump_files(valid[0], 0, False)\n",
    "dump_files(valid[1], 1, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
