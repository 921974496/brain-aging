# rm -rf .smt /local/dhaziza && mkdir /local/dhaziza
# smt init -e python -m run.py -c store-diff -s /local/dhaziza/records dhaziza -d /local/dhaziza/data -l cmdline
#CUDA_VISIBLE_DEVICES=2 smt run -r "(new) AD v HC baseline" --config configs/example_config.yaml -S /local/dhaziza/data -a fit
#CUDA_VISIBLE_DEVICES=5 python run.py --config configs/example_config.yaml -S /local/dhaziza/data -a fit

class: src.estimator.Estimator
params:
  sumatra_outcome_config:
    reason: null
    tags: null
  input_fn_config: # Parameters for input generation (gen_input_fn)
    data_provider: py_streaming
    image_shape: [91, 109, 91]
    py_streaming:
      batch_size: 12
      seed: 0
      classes: 2
      data_paths:
        datadir: '/local/ADNI_AIBL/ADNI_AIBL_T1_normalized/train_NC_AD/'
        class_labels: '/local/ADNI_AIBL/ADNI_AIBL_T1_normalized/py2/AIBL_ADNI_class_labels_T1_NC_AD.pkl'
        valid_data: '/local/ADNI_AIBL/ADNI_AIBL_T1_normalized/py2/AIBL_ADNI_valid_T1_NC_AD.pkl'
        train_data: '/local/ADNI_AIBL/ADNI_AIBL_T1_normalized/py2/AIBL_ADNI_train_T1_NC_AD.pkl'
        regex: '_normalized\.nii\.gz'
        split_on: '_normalized.nii.gz'
    data_generation:
      data_converted_directory: data/ready/
      train_database_file: train.tfrecord
      test_database_file: test.tfrecord
      dataset_compression: GZIP
      test_set_size_ratio: 0.2
      train_test_split_on_feature: study_patient_id
      test_set_random_seed: 0
      image_normalization:
        enable: True
        outlier_percentile: 99
      data_sources:
        - name: ADNI_AIBL
          # Skip augmented data. Example file '273666_normalized.nii.gz'
          glob: /local/ADNI_AIBL/ADNI_AIBL_T1_normalized/train/[0-9]*[0-9]_normalized*
          features_from_filename:
            regexp: .*/(\d+)_normalized\.nii\.gz
            features_group:
              study_image_id: 1
          patients_features: data/raw/csv/adni_aibl__ad_hc.csv
        # - name: PPMI
        #   glob: /local/PPMI/02_registered/I*.nii.gz
        #   features_from_filename:
        #     regexp: .*/I(\d+)\.nii\.gz
        #     features_group:
        #       study_image_id: 1
        #   patients_features: data/raw/csv/ppmi.csv
        # - name: KOLN_T1
        #   glob: data/raw/KOLN_T1/*/*/*.nii.gz
        #   features_from_filename:
        #     regexp: .*/(\d+)/(\d+)_t1\.nii\.gz
        #     features_group:
        #       study_image_id: 1
        #       study_patient_id: 2
        #   patients_features: data/raw/csv/koln.csv

    data_streaming:
      dataset:
        - call: prefetch
          buffer_size: 400
        - call: shuffle
          buffer_size: 500
        - call: map
          map_func: src.data.providers.tf_streaming.parser
          num_parallel_calls: 8
        - call: map
          map_func: src.data.providers.tf_streaming.random_crop
          num_parallel_calls: 8
        - call: batch
          batch_size: 8
  params: # Params for model (model_fn)
    train_log_every_n_iter: 60
    hooks:
      - class: src.train_hooks.SessionHookFullTrace
        params:
            ckptdir: null
            every_step: null
            first_step: True
    network_body: {}
    network_heads:
      # autoencoder:
      #   class: src.heads.autoencoder.AutoencoderHead
      #   loss_weight_in_global_loss: 0.5
      #   head_l1_regularization: null
      #   train_only_globally: True
      # regressor:
      #   class: src.heads.regression.RegressionHead
      #   predict:
      #     - feature: age
      #       average: 75
      #   loss_weight_in_global_loss: null
      #   head_l1_regularization: null
      #   train_only_globally: False
      classifier:
        class: src.heads.classification.ClassificationHead
        predict:
          - health_ad
          - healthy
        loss_weight_in_global_loss: 1.0
        head_l1_regularization: null
        train_only_globally: True
      # adversarial:
      #   class: src.heads.categorical_variable_classification.CategoricalVariableClassificationHead
      #   predict: study_patient_id
      #   num_buckets: 200
      #   loss_weight_in_global_loss: null  # <= 0 for adv network
      #   head_l1_regularization: null
      #   train_only_globally: False
    network_train_ops_settings:
      alternative_training_steps: 0  # 1280
      adam_aggregation_method: EXPERIMENTAL_ACCUMULATE_N
  run_config:
    num_epochs: 15
    validations_per_epoch: 2
    stats_backward_compatibility:
      # Classifier eval
      eval/classifier/accuracy: accuracy
      eval/classifier/false_negatives: false_negatives
      eval/classifier/false_positives: false_positives
      # Classifier training
      train/classifier/accuracy: train/accuracy
      train/classifier/false_negatives: train/false_negatives
      train/classifier/false_positives: train/false_positives
      # Global variables
      train/global_step: global_step
      train/adversarial/loss: adv_loss
      # Losses
      eval/global_optimizer_loss: opt_loss
      train/global_optimizer_loss: train/opt_loss
      eval/loss: loss
      train/classifier/loss: train/loss
      train/regressor/loss: train/loss
    # Tensorflow RunConfig
    # https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig
    tf_estimator_run_config:
      save_summary_steps: 100
      tf_random_seed: 40
      save_checkpoints_steps: 500
      #save_checkpoints_secs:
      log_step_count_steps: 100
      keep_checkpoint_max: 2
      session_config:
        allow_soft_placement: True
        gpu_options:
          per_process_gpu_memory_fraction: 0.9
          allow_growth: False
